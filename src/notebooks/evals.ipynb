{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_configs = {\n",
    "    \"base_url\": \"https://nitoropenai.openai.azure.com/\",\n",
    "    \"model_deployment\": \"gpt-4\",\n",
    "    \"model_name\": \"gpt-4\",\n",
    "    \"embedding_deployment\": \"text-embedding-ada-002\",\n",
    "    \"embedding_name\": \"text-embedding-ada-002\",  # most likely\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "\n",
    "azure_llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_configs[\"base_url\"],\n",
    "    azure_deployment=azure_configs[\"model_deployment\"],\n",
    "    model=azure_configs[\"model_name\"],\n",
    "    validate_base_url=False,\n",
    ")\n",
    "\n",
    "# init the embeddings for answer_relevancy, answer_correctness and answer_similarity\n",
    "azure_embeddings = AzureOpenAIEmbeddings(\n",
    "    model=azure_configs[\"embedding_name\"],\n",
    ")\n",
    "\n",
    "azure_llm = LangchainLLMWrapper(azure_llm)\n",
    "azure_embeddings = LangchainEmbeddingsWrapper(azure_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\"\n",
    "Based solely on the provided text, several misconceptions hinder young founders:\\n\\n1. **Misunderstanding of \\\"Work Experience\\\":**  Young founders often misunderstand the meaning of \\\"work experience.\\\" They may believe it refers to specific skills or expertise, rather than the elimination of childhood habits like \\\"flaking\\\" and the development of an understanding of the inherently difficult nature of work and its relationship to money. This misunderstanding can lead them to underestimate the importance of developing these crucial attributes.\\n\\n2. **Overemphasis on Effort over Results:** Young founders may believe that hard work alone guarantees success, a misconception stemming from the \\\"good effort\\\" reward system in school.  The text explicitly states that the market doesn't reward effort; it rewards results that meet user needs. This misunderstanding can lead to wasted time and resources on projects that don't deliver value.\\n\\n3. **Naive View of Wealth:**  The text suggests that young founders may equate wealth with superficial things like Ferraris and admiration, rather than understanding its true value as a means to escape the \\\"brutal equation\\\" of working long hours to avoid starvation. This limited perspective can affect their motivation and strategic decision-making.\\n\\n4. **Underestimating the Importance of User Focus:**  The text implies that young founders, lacking experience in the relationship between work and money, may not automatically focus on the user's needs.  This lack of focus can lead to the development of products or services that fail to meet market demands.\\n\\n5. **Ignoring the Importance of Adaptability:** The text highlights that many startups end up doing something different than initially planned.  A rigid, pre-ordained plan, coupled with significant spending, is detrimental.  Young founders may not fully grasp the need for flexibility and adaptation in their approach.\\n\\n\\nIn summary, young founders often hold misconceptions about the nature of work, the value of wealth, the importance of user focus, and the need for adaptability. These misconceptions can lead to inefficient resource allocation, a lack of focus on user needs, and ultimately, hinder their progress in building successful startups.\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics._factual_correctness import FactualCorrectness\n",
    "\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    response=\"The Eiffel Tower is located in Paris.\",\n",
    "    reference=\"The Eiffel Tower is located in Paris. I has a height of 1000ft.\"\n",
    ")\n",
    "\n",
    "scorer = FactualCorrectness()\n",
    "scorer.llm = azure_llm\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459876223990668"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import SingleTurnSample \n",
    "from ragas.metrics import ResponseRelevancy\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "        user_input=\"What common misconceptions do young founders (e.g., recent college graduates) have about building successful startups, and how do these misconceptions hinder their progress?\",\n",
    "        response=answer,\n",
    "    )\n",
    "\n",
    "scorer = ResponseRelevancy()\n",
    "scorer.llm = azure_llm\n",
    "scorer.embeddings = azure_embeddings\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9379679986573374"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import SemanticSimilarity\n",
    "\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    response=\"The Eiffel Tower is located in Paris.\",\n",
    "    reference=\"The Eiffel Tower is located in Paris. I has a height of 1000ft.\"\n",
    ")\n",
    "\n",
    "scorer = SemanticSimilarity()\n",
    "scorer.embeddings = azure_embeddings\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8918918918918919"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics._string import NonLLMStringSimilarity\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    response=\"The Eiffel Tower is located in India.\",\n",
    "    reference=\"The Eiffel Tower is located in Paris.\"\n",
    ")\n",
    "\n",
    "scorer = NonLLMStringSimilarity()\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import SimpleCriteriaScore\n",
    "\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    response=\"The Eiffel Tower is located in France.\",\n",
    "    reference=\"The Eiffel Tower is located in France.\"\n",
    ")\n",
    "\n",
    "scorer =  SimpleCriteriaScore(\n",
    "    name=\"course_grained_score\", \n",
    "    definition=\"Score 0 to 5 by similarity, 0 is the lowest and 5 is the highest\",\n",
    "    llm=azure_llm\n",
    ")\n",
    "\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "correctness_metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n",
    "        \"You should also heavily penalize omission of detail\",\n",
    "        \"Vague language, or contradicting OPINIONS, are OK\",\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class DEAzureOpenAI(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        model_name\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.model_name\n",
    "\n",
    "\n",
    "# gpt_35 = AzureChatOpenAI(\n",
    "#     openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "#     azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_GPT_35\"),\n",
    "#     azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "#     openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "# )\n",
    "azure_llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_configs[\"base_url\"],\n",
    "    azure_deployment=azure_configs[\"model_deployment\"],\n",
    "    model=azure_configs[\"model_name\"],\n",
    "    validate_base_url=False,\n",
    ")\n",
    "\n",
    "# gpt_35 = DEAzureOpenAI(model=gpt_35, model_name=\"Azure OpenAI GPT-3.5\")\n",
    "gpt_4 = DEAzureOpenAI(model=azure_llm, model_name=\"Azure OpenAI GPT-4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "correctness_metric = GEval(\n",
    "    model=gpt_4,\n",
    "    name=\"Correctness\",\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n",
    "        \"You should also heavily penalize omission of detail\",\n",
    "        \"Vague language, or contradicting OPINIONS, are OK\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\"The provided text states that the decrease in the percentage of inherited wealth among the richest Americans from 1982 to 2020 is not due to increased inheritance taxes; in fact, these taxes decreased significantly during that period.  Instead, the decline is attributed to the rise in the number of people creating new fortunes.  This increase in newly created wealth is primarily driven by two factors:\\n\\n1. **Company Founding:**  Approximately three-quarters of new fortunes in 2020 stemmed from founding companies or early employee equity.  This contrasts sharply with 1982, where inheritance was the dominant source of wealth for the richest individuals.\\n\\n2. **Investment Management:**  Another significant factor is the rise of successful investment fund managers.  While hedge funds and private equity firms existed in 1982, none of their founders were wealthy enough to be among the top 100 richest Americans at that time.  By 2020, however, 17 of the 73 new fortunes were attributable to managing investment funds.  This reflects both the development of new high-return investment strategies and increased investor trust in these fund managers.\\n\\nIn summary, the shift away from inherited wealth as the primary source of riches among the Forbes 400 between 1982 and 2020 is primarily explained by the substantial increase in wealth creation through company founding and successful investment management, not by changes in inheritance tax laws.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90486432fa71462caeef4cfd879ad5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "The actual output accurately identifies the main reasons for the decline in inherited wealth in line with the expected output, but omits detail about the role of tech sector and the decreasing cost of starting businesses due to technological advancements.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "...\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What were the main reasons for the decline in inherited wealth as the primary source of riches among the Forbes 400 between 1982 and 2020?\",\n",
    "    actual_output=answer,\n",
    "    expected_output=\"The decline in inherited wealth isn't due to increased inheritance taxes (which actually decreased during this period).  Instead, it's primarily because more people are creating new fortunes through starting companies and investing, especially in the tech sector. This shift is largely attributed to the decreasing cost of starting businesses, driven by technological advancements, and the rise of new, high-growth industries. The rise of venture capital and private equity has also played a significant role, providing funding and expertise to help startups scale rapidly.  Essentially, the opportunities for creating wealth through entrepreneurship and investment have expanded significantly, outpacing the accumulation of wealth through inheritance.\"\n",
    ")\n",
    "\n",
    "correctness_metric.measure(test_case)\n",
    "print(correctness_metric.score)\n",
    "print(correctness_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
