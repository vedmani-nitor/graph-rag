{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weave version 0.51.23 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: vedmanivaidya.\n",
      "View Weave data at https://wandb.ai/vedmanivaidya/graphrag-poc/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.trace.weave_client.WeaveClient at 0x26d24eade90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "weave.init(\"graphrag-poc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    " \n",
    "# # Configure logging to write to a file, setting the level to INFO\n",
    "# logging.basicConfig(level=logging.DEBUG,\n",
    "#                     format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "#                     filename='app.log',  # Log messages are written to this file\n",
    "#                     filemode='a')  # Append mode\n",
    " \n",
    "# # Create a StreamHandler to output logs to the console as well\n",
    "# console_handler = logging.StreamHandler()\n",
    "# console_handler.setLevel(logging.DEBUG)  # Set the log level for the console\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# console_handler.setFormatter(formatter)\n",
    " \n",
    "# # Add the console handler to the root logger\n",
    "# logging.getLogger('').addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_llm = AzureOpenAI(\n",
    "    model=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "    deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "openai_embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    # deployment_name=\"my-custom-embedding\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    ")\n",
    "embeddings = openai_embed_model.get_text_embedding(\"Hello, world!\")\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash-latest\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "gemini_embed_model = GeminiEmbedding()\n",
    "embeddings = gemini_embed_model.get_text_embedding(\"Hello, world!\")\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = gemini_llm\n",
    "Settings.embed_model = gemini_embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"D:\\projects\\graphrag-poc\\data\\selection 1\"\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphrag_poc.custom_llama_index.custom_neo4j_property_graph import Neo4jPropertyGraphStore\n",
    "\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"12345678\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    database=\"graphrag-openai-custom-extractor-prompt-gemini\",\n",
    "    refresh_schema=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "len(nodes)\n",
    "# create a list of lists each of 10 nodes\n",
    "nodes_list = [nodes[i : i + 10] for i in range(0, len(nodes), 10)]\n",
    "print(len(nodes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\n",
    "    \"You are a knowledge graph expert specializing in extracting structured information from text about startup founders, companies, and entrepreneurship guidance, particularly from Paul Graham's writings.\"\n",
    "    \"\\nYour task is to extract up to {max_knowledge_triplets} knowledge triplets from the provided text. \"\n",
    "    \"\\n If there are more triplets that can be extracted, then extract as many as needed to capture all the information\"\n",
    "    \"A knowledge triplet consists of (head, relation, tail) along with their types and properties.\"\n",
    "    \"\\n\\nCONTEXT AWARENESS:\"\n",
    "    \"\\n- Focus on startup-related entities: founders, companies, investors, concepts\"\n",
    "    \"\\n- Identify key entrepreneurship principles and advice\"\n",
    "    \"\\n- Capture relationships between people, organizations, and ideas\"\n",
    "    \"\\n- Extract time-sensitive information when available (founded_date, funding_rounds, etc.)\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"INITIAL ONTOLOGY:\\n\"\n",
    "    \"Entity Types: {allowed_entity_types}\\n\"\n",
    "    \"Entity Properties: {allowed_entity_properties}\\n\"\n",
    "    \"Relation Types: {allowed_relation_types}\\n\"\n",
    "    \"Relation Properties: {allowed_relation_properties}\\n\"\n",
    "    \"\\n\"\n",
    "    \"Use these types as a starting point, but introduce new types if necessary based on the context.\\n\"\n",
    "    \"If the Entity Properties, Relation Properties contain property 'description', generate a context aware detailed description, which will have some uniqe non generic information addition\"\n",
    "    \"\\n\"\n",
    "    \"GUIDELINES:\\n\"\n",
    "    \"- Output in JSON format: [{{'head': '', 'head_type': '', 'head_props': {{...}}, 'relation': '', 'relation_props': {{...}}, 'tail': '', 'tail_type': '', 'tail_props': {{...}}}}]\\n\"\n",
    "    \"- Use the most complete form for entities (e.g., 'United States of America' instead of 'USA') but where its ambiguous, use the entity as it is\\n\"\n",
    "    \"- Keep entities concise\\n\"\n",
    "    \"- While writing description property for entities and relations keep context in mind and just dont write the description of the entity or relation, but the description of the entity or relation in the context of the text\\n\"\n",
    "    \"- Ensure the knowledge graph is coherent and easily understandable\\n\"\n",
    "    \"- While extracting relation, use singular form of the relation. Use EXPAND instead of EXPANDS or EXPECT instead of EXPECTS\\n\"\n",
    "    \"- The goal is to make relations as generics as possible, so that there are less duplicate relations in the graph, which have same meaning\\n\"\n",
    "    \"- If there are two names present in the text treat them as separate entities. For example Jessica Livingston and Robert Morris then they are two separate entities Jessica Livingston, Robert Morris\\n\"\n",
    "    \"- Focus on startup-specific metrics and relationships (funding rounds, valuations, mentor relationships)\\n\"\n",
    "    \"- Capture temporal aspects of relationships when mentioned (founding dates, acquisition dates)\\n\"\n",
    "    \"- Include relevant contextual properties (industry sector, technology stack, market focus)\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"EXAMPLE:\\n\"\n",
    "    \"Text Input: \\nTim Cook, CEO of Apple Inc., announced the new Apple Watch that monitors heart health. \"\n",
    "    \"UC Berkeley researchers studied the benefits of apples.\\n\"\n",
    "    \"Example Output:\\n\"\n",
    "    \"[{{'head': 'Tim Cook', 'head_type': 'PERSON', 'head_props': {{'description': 'Technology executive who made the product announcement for Apple Watch, demonstrating leadership in health-focused technology initiatives'}}, 'relation': 'CEO_OF', 'relation_props': {{'description': 'Executive leadership role involving product announcements and strategic health technology initiatives'}}, 'tail': 'Apple Inc.', 'tail_type': 'COMPANY', 'tail_props': {{'description': 'Technology company expanding into health monitoring through wearable devices'}}}},\\n\"\n",
    "    \" {{'head': 'Apple Inc.', 'head_type': 'COMPANY', 'head_props': {{'description': 'Company developing health-focused consumer technology products under Tim Cook's leadership'}}, 'relation': 'PRODUCE', 'relation_props': {{'description': 'Strategic initiative to enter health monitoring market through consumer devices'}}, 'tail': 'Apple Watch', 'tail_type': 'PRODUCT', 'tail_props': {{'description': 'Health-focused smartwatch representing Apple's expansion into medical monitoring technology'}}}},\\n\"\n",
    "    \" {{'head': 'Apple Watch', 'head_type': 'PRODUCT', 'head_props': {{'description': 'Wearable device specifically designed to track and monitor user health metrics'}}, 'relation': 'MONITOR', 'relation_props': {{'description': 'Continuous health monitoring capability focusing on cardiac metrics'}}, 'tail': 'heart health', 'tail_type': 'HEALTH_METRIC', 'tail_props': {{'description': 'Critical health metric monitored through Apple Watch's advanced sensors'}}}},\\n\"\n",
    "    \" {{'head': 'UC Berkeley', 'head_type': 'UNIVERSITY', 'head_props': {{'description': 'Academic institution conducting research on nutritional benefits and health impacts'}}, 'relation': 'STUDY', 'relation_props': {{'description': 'Academic research focusing on health benefits and nutritional value analysis'}}, 'tail': 'benefits of apples', 'tail_type': 'RESEARCH_TOPIC', 'tail_props': {{'description': 'Scientific investigation into the health advantages and nutritional properties of apples'}}}}]\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"MAKE SURE TO FOLLOW THE EXAMPLE FORMAT STRICTLY FOR EACH KNOWLEDGE TRIPLET AND GIVE THE OUTPUT IN JSON LIST FORMAT ONLY AS ITS PARSED USING CODE AND IT NEEDS TO MATCH THE EXAMPLE FORMAT STRICTLY\"\n",
    "    \"Text: {text}\\n\"\n",
    "    \"Output:\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Tuple\n",
    "import re\n",
    "import json\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    Relation,\n",
    ")\n",
    "\n",
    "def parse_dynamic_triplets_with_props(\n",
    "    llm_output: str,\n",
    ") -> List[Tuple[EntityNode, Relation, EntityNode]]:\n",
    "    \"\"\"\n",
    "    Parse the LLM output and convert it into a list of entity-relation-entity triplets.\n",
    "    This function is flexible and can handle various output formats.\n",
    "\n",
    "    Args:\n",
    "        llm_output (str): The output from the LLM, which may be JSON-like or plain text.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[EntityNode, Relation, EntityNode]]: A list of triplets.\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "\n",
    "    try:\n",
    "        #first extract the json from markdown\n",
    "        llm_output = re.search(r'```json\\s*([\\s\\S]*)\\s*```', llm_output).group(1)\n",
    "        # Attempt to parse the output as JSON\n",
    "        data = json.loads(llm_output)\n",
    "        for item in data:\n",
    "            head = item.get(\"head\")\n",
    "            head_type = item.get(\"head_type\")\n",
    "            head_props = item.get(\"head_props\", {})\n",
    "            relation = item.get(\"relation\")\n",
    "            relation_props = item.get(\"relation_props\", {})\n",
    "            tail = item.get(\"tail\")\n",
    "            tail_type = item.get(\"tail_type\")\n",
    "            tail_props = item.get(\"tail_props\", {})\n",
    "\n",
    "            if head and head_type and relation and tail and tail_type:\n",
    "                head_node = EntityNode(\n",
    "                    name=head, label=head_type, properties=head_props\n",
    "                )\n",
    "                tail_node = EntityNode(\n",
    "                    name=tail, label=tail_type, properties=tail_props\n",
    "                )\n",
    "                relation_node = Relation(\n",
    "                    source_id=head_node.id,\n",
    "                    target_id=tail_node.id,\n",
    "                    label=relation,\n",
    "                    properties=relation_props,\n",
    "                )\n",
    "                triplets.append((head_node, relation_node, tail_node))\n",
    "    except json.JSONDecodeError:\n",
    "        # Flexible pattern to match the key-value pairs for head, head_type, head_props, relation, relation_props, tail, tail_type, and tail_props\n",
    "        pattern = r'[\\{\"\\']head[\\}\"\\']\\s*:\\s*[\\{\"\\'](.*?)[\\}\"\\']\\s*,\\s*[\\{\"\\']head_type[\\}\"\\']\\s*:\\s*[\\{\"\\'](.*?)[\\}\"\\']\\s*,\\s*[\\{\"\\']head_props[\\}\"\\']\\s*:\\s*\\{(.*?)\\}\\s*,\\s*[\\{\"\\']relation[\\}\"\\']\\s*:\\s*[\\{\"\\'](.*?)[\\}\"\\']\\s*,\\s*[\\{\"\\']relation_props[\\}\"\\']\\s*:\\s*\\{(.*?)\\}\\s*,\\s*[\\{\"\\']tail[\\}\"\\']\\s*:\\s*[\\{\"\\'](.*?)[\\}\"\\']\\s*,\\s*[\\{\"\\']tail_type[\\}\"\\']\\s*:\\s*[\\{\"\\'](.*?)[\\}\"\\']\\s*,\\s*[\\{\"\\']tail_props[\\}\"\\']\\s*:\\s*\\{(.*?)\\}\\s*'\n",
    "\n",
    "        # Find all matches in the output\n",
    "        matches = re.findall(pattern, llm_output)\n",
    "\n",
    "        for match in matches:\n",
    "            (\n",
    "                head,\n",
    "                head_type,\n",
    "                head_props,\n",
    "                relation,\n",
    "                relation_props,\n",
    "                tail,\n",
    "                tail_type,\n",
    "                tail_props,\n",
    "            ) = match\n",
    "\n",
    "            # Use more robust parsing for properties\n",
    "            def parse_props(props_str: str) -> Dict[str, Any]:\n",
    "                try:\n",
    "                    # Handle mixed quotes and convert to a proper dictionary\n",
    "                    props_str = props_str.replace(\"'\", '\"')\n",
    "                    return json.loads(f\"{{{props_str}}}\")\n",
    "                except json.JSONDecodeError:\n",
    "                    return {}\n",
    "\n",
    "            head_props_dict = parse_props(head_props)\n",
    "            relation_props_dict = parse_props(relation_props)\n",
    "            tail_props_dict = parse_props(tail_props)\n",
    "\n",
    "            head_node = EntityNode(\n",
    "                name=head, label=head_type, properties=head_props_dict\n",
    "            )\n",
    "            tail_node = EntityNode(\n",
    "                name=tail, label=tail_type, properties=tail_props_dict\n",
    "            )\n",
    "            relation_node = Relation(\n",
    "                source_id=head_node.id,\n",
    "                target_id=tail_node.id,\n",
    "                label=relation,\n",
    "                properties=relation_props_dict,\n",
    "            )\n",
    "            triplets.append((head_node, relation_node, tail_node))\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import DynamicLLMPathExtractor\n",
    "\n",
    "dyn_llm_path_extractor = DynamicLLMPathExtractor(\n",
    "    llm=Settings.llm,\n",
    "    allowed_entity_props=[\"description\"],\n",
    "    allowed_relation_props=[\"description\"],\n",
    "    extract_prompt=prompt_template,\n",
    "    parse_fn=parse_dynamic_triplets_with_props,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.vector_stores.neo4jvector import Neo4jVectorStore\n",
    "# neo4j_vector = Neo4jVectorStore(\n",
    "#     username=\"neo4j\",\n",
    "#     password=\"12345678\",\n",
    "#     url=\"bolt://localhost:7687\",\n",
    "#     database=\"graphrag-openai-custom-extractor-prompt-gemini\",\n",
    "#     hybrid_search = True,\n",
    "#     embedding_dimension=768\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "# from llama_index.core.indices.property_graph import SimpleLLMPathExtractor\n",
    "\n",
    "# index = PropertyGraphIndex(\n",
    "#     nodes_list[0],\n",
    "#     embed_model=Settings.embed_model,\n",
    "#     kg_extractors=[dyn_llm_path_extractor],\n",
    "#     property_graph_store=graph_store,\n",
    "#     show_progress=True,\n",
    "# )\n",
    "\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    # vector_store=neo4j_vector,\n",
    "    property_graph_store=graph_store,\n",
    "    llm=Settings.llm,\n",
    "    embed_model=Settings.embed_model,\n",
    "    kg_extractors=[dyn_llm_path_extractor],\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index._insert_nodes(nodes_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index._insert_nodes(nodes_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# index._insert_nodes(nodes_list[3])\n",
    "# time.sleep(60)\n",
    "# index._insert_nodes(nodes_list[4])\n",
    "# time.sleep(60)\n",
    "# index._insert_nodes(nodes_list[5])\n",
    "# time.sleep(60)\n",
    "# index._insert_nodes(nodes_list[6])\n",
    "# time.sleep(60)\n",
    "# index._insert_nodes(nodes_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_store.structured_query(\"\"\"\n",
    "# CREATE VECTOR INDEX entity IF NOT EXISTS\n",
    "# FOR (m:`__Entity__`)\n",
    "# ON m.embedding\n",
    "# OPTIONS {indexConfig: {\n",
    "#  `vector.dimensions`: 1536,\n",
    "#  `vector.similarity_function`: 'cosine'\n",
    "# }}\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_threshold = 0.9\n",
    "# word_edit_distance = 4\n",
    "# data = graph_store.structured_query(\"\"\"\n",
    "# MATCH (e:__Entity__)\n",
    "# CALL {\n",
    "#   WITH e\n",
    "#   CALL db.index.vector.queryNodes('entity', 10, e.embedding)\n",
    "#   YIELD node, score\n",
    "#   WITH node, score\n",
    "#   WHERE score > toFLoat($cutoff)\n",
    "#       AND (toLower(node.name) CONTAINS toLower(e.name) OR toLower(e.name) CONTAINS toLower(node.name)\n",
    "#            OR apoc.text.distance(toLower(node.name), toLower(e.name)) < $distance)\n",
    "#       AND labels(e) = labels(node)\n",
    "#   WITH node, score\n",
    "#   ORDER BY node.name\n",
    "#   RETURN collect(node) AS nodes\n",
    "# }\n",
    "# WITH distinct nodes\n",
    "# WHERE size(nodes) > 1\n",
    "# WITH collect([n in nodes | n.name]) AS results\n",
    "# UNWIND range(0, size(results)-1, 1) as index\n",
    "# WITH results, index, results[index] as result\n",
    "# WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n",
    "#         CASE WHEN index <> index2 AND\n",
    "#             size(apoc.coll.intersection(acc, results[index2])) > 0\n",
    "#             THEN apoc.coll.union(acc, results[index2])\n",
    "#             ELSE acc\n",
    "#         END\n",
    "# )) as combinedResult\n",
    "# WITH distinct(combinedResult) as combinedResult\n",
    "# // extra filtering\n",
    "# WITH collect(combinedResult) as allCombinedResults\n",
    "# UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\n",
    "# WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\n",
    "# WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1) \n",
    "#     WHERE x <> combinedResultIndex\n",
    "#     AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n",
    "# )\n",
    "# RETURN combinedResult  \n",
    "# \"\"\", param_map={'cutoff': similarity_threshold, 'distance': word_edit_distance})\n",
    "# for row in data:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import (\n",
    "    LLMSynonymRetriever,\n",
    "    VectorContextRetriever\n",
    ")\n",
    "\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "\n",
    "from graphrag_poc.custom_llama_index.custom_vector_retriever import CustomVectorContextRetriever\n",
    "\n",
    "vector_retriever = VectorContextRetriever(\n",
    "     graph_store,\n",
    "     embed_model=Settings.embed_model,\n",
    "    #  similarity_top_k=4,\n",
    "     path_depth=3,\n",
    "    #  include_text=True,\n",
    "    #  include_properties=True,\n",
    "     similarity_score=0.7\n",
    ")\n",
    "\n",
    "llm_synonym_retriever = LLMSynonymRetriever(\n",
    "    graph_store=graph_store,\n",
    "    include_text=False,\n",
    "    # include_properties=True,\n",
    "    max_keywords=20,\n",
    "    llm=Settings.llm,\n",
    ")\n",
    "\n",
    "custom_vector_retriever = CustomVectorContextRetriever(\n",
    "     graph_store,\n",
    "     embed_model=Settings.embed_model,\n",
    "    #  similarity_top_k=4,\n",
    "     path_depth=3,\n",
    "     include_text=True,\n",
    "     similarity_score=0.7,\n",
    "     limit=100,\n",
    "     similarity_top_k=20,\n",
    "     mode=VectorStoreQueryMode.HYBRID,\n",
    "     hybrid_top_k=20\n",
    ")\n",
    "\n",
    "test_vector_retriever = VectorContextRetriever(\n",
    "     graph_store,\n",
    "     embed_model=Settings.embed_model,\n",
    "    #  similarity_top_k=4,\n",
    "     path_depth=3,\n",
    "     include_text=True,\n",
    "     similarity_score=0.7,\n",
    "     limit=100,\n",
    "     similarity_top_k=20,\n",
    "     mode=VectorStoreQueryMode.HYBRID,\n",
    "     hybrid_top_k=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 query_str: What are the specific advantages of the 'grad student' model for startups, and why is it preferable to the 'law firm' model? It is okay if the answer is lengthy. Its is very critical that the answers are written using information available in the provided data. similarity_top_k: 20 hybrid_top_k: 20\n",
      "The main advantage of the \"grad student\" model is its frugality.  Recent graduates can live very inexpensively, giving them a significant cost advantage over older founders, especially in software startups where the primary expense is personnel.  Older founders with families and mortgages face a considerable disadvantage due to higher living costs.  This low-cost lifestyle allows for daringly low pricing strategies, making the resulting product or service more popular.  This low-cost approach mirrors the success of companies like Apple, whose initial products were inexpensive due to the founders' limited resources.  This inexpensive approach often leads to market disruption, as established players are unable to compete at such low price points.  The \"grad student\" model also fosters a mindset of resourcefulness and innovation, driving the creation of inexpensive and popular products.  Furthermore, younger founders tend to be more mobile and less encumbered by relationships or possessions, making it easier to relocate to startup hubs, which are crucial for success.  Conversely, the implied \"law firm\" model, with its higher expenses and established lifestyle, lacks these advantages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import QueryBundle\n",
    "query_bundle = QueryBundle(\n",
    "    query_str=\"What are the specific advantages of the 'grad student' model for startups, and why is it preferable to the 'law firm' model? It is okay if the answer is lengthy. Its is very critical that the answers are written using information available in the provided data.\"\n",
    ")\n",
    "query_engine = index.as_query_engine(\n",
    "    sub_retrievers=[custom_vector_retriever, llm_synonym_retriever],\n",
    "    # # include_text=True,\n",
    "    # # include_properties=True,\n",
    "    # similarity_top_k=10,\n",
    "    # limit=100,\n",
    "    # similarity_score=0.75,\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"What are the specific advantages of the 'grad student' model for startups, and why is it preferable to the 'law firm' model? It is okay if the answer is lengthy. Its is very critical that the answers are written using information available in the provided data.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='8ae835bc-bf63-43ce-a0ac-ee8869d9aa58', embedding=None, metadata={'file_path': \"D:\\\\projects\\\\graphrag-poc\\\\data\\\\selection 1\\\\A Student's Guide to Startups (HIVE).txt\", 'file_name': \"A Student's Guide to Startups (HIVE).txt\", 'file_type': 'text/plain', 'file_size': 35856, 'creation_date': '2024-11-26', 'last_modified_date': '2024-11-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='89726fb7-4d79-4142-8bd4-c43cac27e169', node_type='4', metadata={'file_path': \"D:\\\\projects\\\\graphrag-poc\\\\data\\\\selection 1\\\\A Student's Guide to Startups (HIVE).txt\", 'file_name': \"A Student's Guide to Startups (HIVE).txt\", 'file_type': 'text/plain', 'file_size': 35856, 'creation_date': '2024-11-26', 'last_modified_date': '2024-11-20'}, hash='c93d2695e878542a3875974944596c8b180c2788d87dcb71a104c6ec2a8753c2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e33dc8f3-f440-4523-bbbd-00f9353a2208', node_type='1', metadata={'file_path': \"D:\\\\projects\\\\graphrag-poc\\\\data\\\\selection 1\\\\A Student's Guide to Startups (HIVE).txt\", 'file_name': \"A Student's Guide to Startups (HIVE).txt\", 'file_type': 'text/plain', 'file_size': 35856, 'creation_date': '2024-11-26', 'last_modified_date': '2024-11-20'}, hash='218e6adda905f6cb3464a6f33e378f4aa149f6465d3b651270eb80dd66ea2d9b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4d711158-13b2-44c7-8030-7c7ba4e8c62d', node_type='1', metadata={}, hash='b0798ee2a0ace2f0ecb8b7fc8dd41ffd14b528511f9d008bc3ddd1fbdc7bb66c')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Here are some facts extracted from the provided text:\\n\\nPaul Graham (Description: Founder of Y Combinator, emphasizing in-person interaction with founders.) -> RECOMMEND (Description: Recommends a frugal \\'grad student\\' model over an expensive \\'law firm\\' model for startups.) -> \\'Grad student\\' model (Description: A frugal and cost-effective approach to startup operations, contrasting with a more expensive and lavish model.)\\n\\nRecent grads can live on practically nothing, and this gives you an edge over older founders, because the main cost in software startups is people. The guys with kids and mortgages are at a real disadvantage. This is one reason I\\'d bet on the 25 year old over the 32 year old. The 32 year old probably is a better programmer, but probably also has a much more expensive life. Whereas a 25 year old has some work experience (more on that later) but can live as cheaply as an undergrad. Robert Morris and I were 29 and 30 respectively when we started Viaweb, but fortunately we still lived like 23 year olds. We both had roughly zero assets. I would have loved to have a mortgage, since that would have meant I had a house But in retrospect having nothing turned out to be convenient. I wasn\\'t tied down and I was used to living cheaply. Even more important than living cheaply, though, is thinking cheaply. One reason the Apple II was so popular was that it was cheap. The computer itself was cheap, and it used cheap, off-the-shelf peripherals like a cassette tape recorder for data storage and a TV as a monitor. And you know why? Because Woz designed this computer for himself, and he couldn\\'t afford anything more. We benefitted from the same phenomenon. Our prices were daringly low for the time. The top level of service was $300 a month, which was an order of magnitude below the norm. In retrospect this was a smart move, but we didn\\'t do it because we were smart. $300 a month seemed like a lot of money to us. Like Apple, we created something inexpensive, and therefore popular, simply because we were poor. A lot of startups have that form: someone comes along and makes something for a tenth or a hundredth of what it used to cost, and the existing players can\\'t follow because they don\\'t even want to think about a world in which that\\'s possible. Traditional long distance carriers, for example, didn\\'t even want to think about VoIP. (It was coming, all the same.) Being poor helps in this game, because your own personal bias points in the same direction technology evolves in. The advantages of rootlessness are similar to those of poverty. When you\\'re young you\\'re more mobileâ€”not just because you don\\'t have a house or much stuff, but also because you\\'re less likely to have serious relationships. This turns out to be important, because a lot of startups involve someone moving. The founders of Kiko, for example, are now en route to the Bay Area to start their next startup. It\\'s a better place for what they want to do. And it was easy for them to decide to go, because neither as far as I know has a serious girlfriend, and everything they own will fit in one carâ€”or more precisely, will either fit in one car or is crappy enough that they don\\'t mind leaving it behind. They at least were in Boston. What if they\\'d been in Nebraska, like Evan Williams was at their age? Someone wrote recently that the drawback of Y Combinator was that you had to move to participate. It couldn\\'t be any other way. The kind of conversations we have with founders, we have to have in person. We fund a dozen startups at a time, and we can\\'t be in a dozen places at once. But even if we could somehow magically save people from moving, we wouldn\\'t. We wouldn\\'t be doing founders a favor by letting them stay in Nebraska. Places that aren\\'t startup hubs are toxic to startups. You can tell that from indirect evidence. You can tell how hard it must be to start a startup in Houston or Chicago or Miami from the microscopically small number, per capita, that succeed there. I don\\'t know exactly what\\'s suppressing all the startups in these townsâ€”probably a hundred subtle little thingsâ€”but something must be. [ 2 ] Maybe this will change. Maybe the increasing cheapness of startups will mean they\\'ll be able to survive anywhere, instead of only in the most hospitable environments. Maybe 37signals is the pattern for the future. But maybe not. Historically there have always been certain towns that were centers for certain industries, and if you weren\\'t in one of them you were at a disadvantage. So my guess is that 37signals is an anomaly. We\\'re looking at a pattern much older than \"Web 2.0\" here.', mimetype='text/plain', start_char_idx=8228, end_char_idx=12436, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8974435329437256),\n",
       " NodeWithScore(node=TextNode(id_='1f39a1b8-a229-41c9-bfaa-f0bec95c4cad', embedding=None, metadata={'file_path': 'D:\\\\projects\\\\graphrag-poc\\\\data\\\\selection 1\\\\Hiring is Obsolete (HIVE).txt', 'file_name': 'Hiring is Obsolete (HIVE).txt', 'file_type': 'text/plain', 'file_size': 26756, 'creation_date': '2024-11-26', 'last_modified_date': '2024-11-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='51ef7dbe-22c4-428a-8d4a-0e464e91cbfd', node_type='4', metadata={'file_path': 'D:\\\\projects\\\\graphrag-poc\\\\data\\\\selection 1\\\\Hiring is Obsolete (HIVE).txt', 'file_name': 'Hiring is Obsolete (HIVE).txt', 'file_type': 'text/plain', 'file_size': 26756, 'creation_date': '2024-11-26', 'last_modified_date': '2024-11-20'}, hash='678510d12f12d6d3ec51a68b0b363bd67e24fd05bbaccb4efeb1732ea3e16552'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b80c101-4a48-4d65-b869-f816d943af32', node_type='1', metadata={}, hash='5899d01b8a0001b3d6e5c03b4f9ed4b5a540b65d1a12f03857f5e437adbd5973')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Here are some facts extracted from the provided text:\\n\\nStartup (Description: Companies that often succeed through acquisition rather than going public, valuing the people behind the technology.) -> HAVE (Description: Possesses a more complicated legal life if investors are not accredited, impacting IPO processes.) -> complicated legal life (Description: Legal status of a startup impacted by the accreditation status of its investors.)\\n\\nMay 2005 (This essay is derived from a talk at the Berkeley CSUA.) The three big powers on the Internet now are Yahoo, Google, and Microsoft. Average age of their founders: 24. So it is pretty well established now that grad students can start successful companies. And if grad students can do it, why not undergrads? Like everything else in technology, the cost of starting a startup has decreased dramatically. Now it\\'s so low that it has disappeared into the noise. The main cost of starting a Web-based startup is food and rent. Which means it doesn\\'t cost much more to start a company than to be a total slacker. You can probably start a startup on ten thousand dollars of seed funding, if you\\'re prepared to live on ramen. The less it costs to start a company, the less you need the permission of investors to do it. So a lot of people will be able to start companies now who never could have before. The most interesting subset may be those in their early twenties. I\\'m not so excited about founders who have everything investors want except intelligence, or everything except energy. The most promising group to be liberated by the new, lower threshold are those who have everything investors want except experience. Market Rate I once claimed that nerds were unpopular in secondary school mainly because they had better things to do than work full-time at being popular. Some said I was just telling people what they wanted to hear. Well, I\\'m now about to do that in a spectacular way: I think undergraduates are undervalued. Or more precisely, I think few realize the huge spread in the value of 20 year olds. Some, it\\'s true, are not very capable. But others are more capable than all but a handful of 30 year olds. [ 1 ] Till now the problem has always been that it\\'s difficult to pick them out. Every VC in the world, if they could go back in time, would try to invest in Microsoft. But which would have then? How many would have understood that this particular 19 year old was Bill Gates? It\\'s hard to judge the young because (a) they change rapidly, (b) there is great variation between them, and (c) they\\'re individually inconsistent. That last one is a big problem. When you\\'re young, you occasionally say and do stupid things even when you\\'re smart. So if the algorithm is to filter out people who say stupid things, as many investors and employers unconsciously do, you\\'re going to get a lot of false positives. Most organizations who hire people right out of college are only aware of the average value of 22 year olds, which is not that high. And so the idea for most of the twentieth century was that everyone had to begin as a trainee in some entry-level job. Organizations realized there was a lot of variation in the incoming stream, but instead of pursuing this thought they tended to suppress it, in the belief that it was good for even the most promising kids to start at the bottom, so they didn\\'t get swelled heads. The most productive young people will always be undervalued by large organizations, because the young have no performance to measure yet, and any error in guessing their ability will tend toward the mean. What\\'s an especially productive 22 year old to do? One thing you can do is go over the heads of organizations, directly to the users. Any company that hires you is, economically, acting as a proxy for the customer. The rate at which they value you (though they may not consciously realize it) is an attempt to guess your value to the user. But there\\'s a way to appeal their judgement. If you want, you can opt to be valued directly by users, by starting your own company. The market is a lot more discerning than any employer. And it is completely non-discriminatory. On the Internet, nobody knows you\\'re a dog. And more to the point, nobody knows you\\'re 22. All users care about is whether your site or software gives them what they want. They don\\'t care if the person behind it is a high school kid. If you\\'re really productive, why not make employers pay market rate for you? Why go work as an ordinary employee for a big company, when you could start a startup and make them buy it to get you? When most people hear the word \"startup,\" they think of the famous ones that have gone public. But most startups that succeed do it by getting bought. And usually the acquirer doesn\\'t just want the technology, but the people who created it as well.', mimetype='text/plain', start_char_idx=0, end_char_idx=4396, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8845250606536865)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Paul Graham (Description: Founder of Y Combinator, emphasizing in-person interaction with founders.) -> RECOMMEND (Description: Recommends a frugal 'grad student' model over an expensive 'law firm' model for startups.) -> 'Grad student' model (Description: A frugal and cost-effective approach to startup operations, contrasting with a more expensive and lavish model.)\n",
      "\n",
      "Recent grads can live on practically nothing, and this gives you an edge over older founders, because the main cost in software startups is people. The guys with kids and mortgages are at a real disadvantage. This is one reason I'd bet on the 25 year old over the 32 year old. The 32 year old probably is a better programmer, but probably also has a much more expensive life. Whereas a 25 year old has some work experience (more on that later) but can live as cheaply as an undergrad. Robert Morris and I were 29 and 30 respectively when we started Viaweb, but fortunately we still lived like 23 year olds. We both had roughly zero assets. I would have loved to have a mortgage, since that would have meant I had a house But in retrospect having nothing turned out to be convenient. I wasn't tied down and I was used to living cheaply. Even more important than living cheaply, though, is thinking cheaply. One reason the Apple II was so popular was that it was cheap. The computer itself was cheap, and it used cheap, off-the-shelf peripherals like a cassette tape recorder for data storage and a TV as a monitor. And you know why? Because Woz designed this computer for himself, and he couldn't afford anything more. We benefitted from the same phenomenon. Our prices were daringly low for the time. The top level of service was $300 a month, which was an order of magnitude below the norm. In retrospect this was a smart move, but we didn't do it because we were smart. $300 a month seemed like a lot of money to us. Like Apple, we created something inexpensive, and therefore popular, simply because we were poor. A lot of startups have that form: someone comes along and makes something for a tenth or a hundredth of what it used to cost, and the existing players can't follow because they don't even want to think about a world in which that's possible. Traditional long distance carriers, for example, didn't even want to think about VoIP. (It was coming, all the same.) Being poor helps in this game, because your own personal bias points in the same direction technology evolves in. The advantages of rootlessness are similar to those of poverty. When you're young you're more mobileâ€”not just because you don't have a house or much stuff, but also because you're less likely to have serious relationships. This turns out to be important, because a lot of startups involve someone moving. The founders of Kiko, for example, are now en route to the Bay Area to start their next startup. It's a better place for what they want to do. And it was easy for them to decide to go, because neither as far as I know has a serious girlfriend, and everything they own will fit in one carâ€”or more precisely, will either fit in one car or is crappy enough that they don't mind leaving it behind. They at least were in Boston. What if they'd been in Nebraska, like Evan Williams was at their age? Someone wrote recently that the drawback of Y Combinator was that you had to move to participate. It couldn't be any other way. The kind of conversations we have with founders, we have to have in person. We fund a dozen startups at a time, and we can't be in a dozen places at once. But even if we could somehow magically save people from moving, we wouldn't. We wouldn't be doing founders a favor by letting them stay in Nebraska. Places that aren't startup hubs are toxic to startups. You can tell that from indirect evidence. You can tell how hard it must be to start a startup in Houston or Chicago or Miami from the microscopically small number, per capita, that succeed there. I don't know exactly what's suppressing all the startups in these townsâ€”probably a hundred subtle little thingsâ€”but something must be. [ 2 ] Maybe this will change. Maybe the increasing cheapness of startups will mean they'll be able to survive anywhere, instead of only in the most hospitable environments. Maybe 37signals is the pattern for the future. But maybe not. Historically there have always been certain towns that were centers for certain industries, and if you weren't in one of them you were at a disadvantage. So my guess is that 37signals is an anomaly. We're looking at a pattern much older than \"Web 2.0\" here.\n",
      "--------------------------------\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Startup (Description: Companies that often succeed through acquisition rather than going public, valuing the people behind the technology.) -> HAVE (Description: Possesses a more complicated legal life if investors are not accredited, impacting IPO processes.) -> complicated legal life (Description: Legal status of a startup impacted by the accreditation status of its investors.)\n",
      "\n",
      "May 2005 (This essay is derived from a talk at the Berkeley CSUA.) The three big powers on the Internet now are Yahoo, Google, and Microsoft. Average age of their founders: 24. So it is pretty well established now that grad students can start successful companies. And if grad students can do it, why not undergrads? Like everything else in technology, the cost of starting a startup has decreased dramatically. Now it's so low that it has disappeared into the noise. The main cost of starting a Web-based startup is food and rent. Which means it doesn't cost much more to start a company than to be a total slacker. You can probably start a startup on ten thousand dollars of seed funding, if you're prepared to live on ramen. The less it costs to start a company, the less you need the permission of investors to do it. So a lot of people will be able to start companies now who never could have before. The most interesting subset may be those in their early twenties. I'm not so excited about founders who have everything investors want except intelligence, or everything except energy. The most promising group to be liberated by the new, lower threshold are those who have everything investors want except experience. Market Rate I once claimed that nerds were unpopular in secondary school mainly because they had better things to do than work full-time at being popular. Some said I was just telling people what they wanted to hear. Well, I'm now about to do that in a spectacular way: I think undergraduates are undervalued. Or more precisely, I think few realize the huge spread in the value of 20 year olds. Some, it's true, are not very capable. But others are more capable than all but a handful of 30 year olds. [ 1 ] Till now the problem has always been that it's difficult to pick them out. Every VC in the world, if they could go back in time, would try to invest in Microsoft. But which would have then? How many would have understood that this particular 19 year old was Bill Gates? It's hard to judge the young because (a) they change rapidly, (b) there is great variation between them, and (c) they're individually inconsistent. That last one is a big problem. When you're young, you occasionally say and do stupid things even when you're smart. So if the algorithm is to filter out people who say stupid things, as many investors and employers unconsciously do, you're going to get a lot of false positives. Most organizations who hire people right out of college are only aware of the average value of 22 year olds, which is not that high. And so the idea for most of the twentieth century was that everyone had to begin as a trainee in some entry-level job. Organizations realized there was a lot of variation in the incoming stream, but instead of pursuing this thought they tended to suppress it, in the belief that it was good for even the most promising kids to start at the bottom, so they didn't get swelled heads. The most productive young people will always be undervalued by large organizations, because the young have no performance to measure yet, and any error in guessing their ability will tend toward the mean. What's an especially productive 22 year old to do? One thing you can do is go over the heads of organizations, directly to the users. Any company that hires you is, economically, acting as a proxy for the customer. The rate at which they value you (though they may not consciously realize it) is an attempt to guess your value to the user. But there's a way to appeal their judgement. If you want, you can opt to be valued directly by users, by starting your own company. The market is a lot more discerning than any employer. And it is completely non-discriminatory. On the Internet, nobody knows you're a dog. And more to the point, nobody knows you're 22. All users care about is whether your site or software gives them what they want. They don't care if the person behind it is a high school kid. If you're really productive, why not make employers pay market rate for you? Why go work as an ordinary employee for a big company, when you could start a startup and make them buy it to get you? When most people hear the word \"startup,\" they think of the famous ones that have gone public. But most startups that succeed do it by getting bought. And usually the acquirer doesn't just want the technology, but the people who created it as well.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "response_nodes: List[NodeWithScore] = response.source_nodes\n",
    "\n",
    "for node in response_nodes:\n",
    "    print(node.get_content())\n",
    "    print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
